# Handoff: Strict SDPB Semantics and Runtime Envelope (2026-02-11)

**Date:** 2026-02-11
**Status:** Branch merged to main, ready for runtime characterization
**Author:** Claude (assisted Oscar)

---

## Executive Summary

The `codex/strict-failfast-stageb-snap-eps` branch has been **merged to main**. This implements:

1. **Strict SDPB failure handling** - inconclusive outcomes (timeout, unknown) are now failures, not "allowed"
2. **Fail-fast Stage A/B** - ANY solver anomaly immediately aborts that point (no silent fallbacks)
3. **Stage B epsilon anchoring** - snaps Stage A Î”Îµ to scalar grid with tolerance enforcement
4. **Hardened merge gates** - blocks Stage B if Stage A data is pathological
5. **End-to-end timeout configuration** - `--sdpb-timeout` exposed and wired through all scripts
6. **Runtime envelope helpers** - single-point characterization, pilot jobs, smoke tests

**All tests passing:** 17 SDPB + 28 Stage A + 30 Stage B = **75/75 âœ“**

**Next step:** Run runtime envelope characterization to find the correct SDPB timeout.

---

## What Changed (Code)

### 1. SDPB Strict Semantics (`src/ising_bootstrap/lp/sdpb.py`)

**Before:**
```python
if "maxComplementarity" in reason:
    # Treated as "allowed"
    return FeasibilityResult(excluded=False, status="...", lp_status=2)

# Timeouts/unknown â†’ treated as "allowed"
return FeasibilityResult(excluded=False, status="...", lp_status=4)
```

**After:**
```python
if "maxComplementarity" in reason:
    # Inconclusive, NOT trusted as allowed
    return FeasibilityResult(
        excluded=False,
        status="SDPB inconclusive (complementarity diverged)",
        lp_status=4,
        success=False  # â† CRITICAL
    )

# Timeouts/unknown â†’ explicit failure
return FeasibilityResult(
    excluded=False,
    status="SDPB inconclusive: {reason}",
    lp_status=4,
    success=False  # â† CRITICAL
)
```

**Impact:** Only explicit feasible/infeasible termination reasons are trusted. Everything else is a solver failure.

---

### 2. Stage A Fail-Fast (`src/ising_bootstrap/scans/stage_a.py`)

**Before:**
```python
consecutive_failures = 0
if not result.success:
    consecutive_failures += 1
    if consecutive_failures >= 3:
        raise RuntimeError(...)
    print("WARNING: Treating as allowed (conservative)")
    return False  # Continue binary search
```

**After:**
```python
if not result.success:
    raise RuntimeError(
        f"Solver failed while testing gap={gap:.6f} at Î”Ïƒ={delta_sigma:.6f}. "
        f"Failure: {result.status}"
    )
# No fallback, no retry
```

**Impact:** ANY solver failure â†’ point fails immediately with NaN written to CSV.

**This is VERY strict** but correct once timeout is properly configured.

---

### 3. Stage B Epsilon Anchoring (`src/ising_bootstrap/scans/stage_b.py`)

**Problem:** Stage A Î”Îµ (e.g., 1.41234) may not exactly match a scalar grid point (e.g., 1.41000, 1.42000).

**Solution:**
```python
def _snap_delta_eps_to_scalar_grid(delta_eps, scalar_deltas, scalar_mask, tolerance):
    """Snap Stage A Î”Îµ to nearest scalar grid point."""
    scalar_grid = scalar_deltas[scalar_mask]
    nearest_idx = np.argmin(np.abs(scalar_grid - delta_eps))
    snapped = scalar_grid[nearest_idx]

    if abs(snapped - delta_eps) > tolerance:
        raise RuntimeError(f"Cannot anchor Î”Îµ={delta_eps:.6f} to scalar grid...")

    return snapped

# Then enforce exactly one scalar at anchored epsilon
scalar_at_eps = scalar_mask & np.isclose(scalar_deltas, delta_eps_anchored, atol=1e-10)
if np.sum(scalar_at_eps) != 1:
    raise RuntimeError("Expected exactly one anchored Îµ scalar...")
```

**Impact:** Stage B now has a well-defined anchor scalar that MUST be included in the constraint matrix.

---

### 4. Merge Gate Hardening (`jobs/merge_stage_a_and_submit_b.slurm`)

**New validation:**
```python
# Python validation script embedded in SLURM
valid = 0
nonfinite = 0
near_lower = 0  # < 0.51
near_upper = 0  # > 2.49

for row in Stage A CSV:
    if not isfinite(value):
        nonfinite += 1
    elif value < 0.51:
        near_lower += 1
    elif value > 2.49:
        near_upper += 1
    else:
        valid += 1

# Block Stage B if:
if valid < 10:            abort("Too few valid rows")
if nonfinite > 0:         abort("Non-finite values present")
if near_lower == valid:   abort("All at unitarity floor ~0.5")
if near_upper == valid:   abort("All at upper bound ~2.5")
```

**Impact:** Stage B only launches if Stage A data is healthy.

---

### 5. Timeout Configuration

**Exposed in CLIs:**
```bash
# Stage A
python -m ising_bootstrap.scans.stage_a \
    --sdpb-timeout 1800 \
    ...

# Stage B
python -m ising_bootstrap.scans.stage_b \
    --sdpb-timeout 1800 \
    --eps-snap-tolerance 1e-3 \
    ...
```

**Wired through SLURM:**
```bash
# Stage A array job
sbatch --export=ALL,SDPB_TIMEOUT=1800,STAGE_A_TOLERANCE=1e-4 \
    jobs/stage_a_sdpb.slurm

# Stage B array job
sbatch --export=ALL,SDPB_TIMEOUT=1800,STAGE_B_TOLERANCE=1e-3,EPS_SNAP_TOLERANCE=1e-3 \
    jobs/stage_b_sdpb.slurm
```

**Default timeout:** Changed from 600s (10 min) â†’ **1800s (30 min)**

---

## What Changed (Infrastructure)

### New Helper Scripts

1. **`jobs/submit_stage_a_runtime_envelope.sh`**
   Single-point characterization at Î”Ïƒ=0.518 (the challenging point)
   ```bash
   bash jobs/submit_stage_a_runtime_envelope.sh
   TIMEOUT=3600 bash jobs/submit_stage_a_runtime_envelope.sh
   TIMEOUT=3600 CPUS=16 MEM=160G bash jobs/submit_stage_a_runtime_envelope.sh
   ```

2. **`jobs/stage_a_pilot_sdpb.slurm`** + **`jobs/merge_stage_a_pilot.sh`**
   5-point pilot workflow before full 51-task array
   ```bash
   sbatch --array=0,9,18,27,36 \
     --export=ALL,SDPB_TIMEOUT=1800 \
     jobs/stage_a_pilot_sdpb.slurm
   bash jobs/merge_stage_a_pilot.sh
   ```

3. **`jobs/stage_b_smoke_sdpb.slurm`** + **`jobs/submit_stage_b_smoke.sh`**
   Single-point Stage B smoke test
   ```bash
   bash jobs/submit_stage_b_smoke.sh
   ```

### Updated SLURM Scripts

| Script | Old | New | Notes |
|--------|-----|-----|-------|
| `stage_a_sdpb.slurm` | 64G, 8h, timeout=600s | 128G, 12h, timeout=1800s | Configurable via env vars |
| `stage_b_sdpb.slurm` | - | timeout=1800s, eps_snap_tolerance=1e-3 | Wired through env vars |
| `test_sufficient_memory.slurm` | 2h | 6h, timeout=1800s | For envelope characterization |
| `merge_stage_a_and_submit_b.slurm` | Simple row count | Full validation + gate | Python validation script |

---

## Test Results

All tests passing after merge:

```bash
$ PYTHONPATH=src pytest tests/test_lp/test_sdpb.py -q
17 passed in 11.90s

$ PYTHONPATH=src pytest tests/test_scans/test_stage_a.py -q
28 passed in X.XXs  # Including new TestFailureHandling

$ PYTHONPATH=src pytest tests/test_scans/test_stage_b.py -q
30 passed in 29.96s  # Including epsilon anchoring tests
```

**Total: 75/75 tests passing âœ“**

---

## Current Status (2026-02-11)

### What We Know

1. **Error handling fix is working** âœ“
   Test job 59829443 correctly detected 3 SDPB timeouts and aborted with:
   ```
   ERROR: SDPB solver failed 3 consecutive times.
   Last failure: SDPB timed out after 600s
   ```

2. **SDPB is NOT crashing** âœ“
   - No OOM (used 70.6 GB / 128 GB allocated)
   - No MPI errors
   - Simply running too slow for 10-minute timeout

3. **Problem size is LARGE**
   - 520,476 operators â†’ 470,476 SDP blocks (after first gap)
   - pmp2sdp: ~5 minutes per iteration
   - SDPB solve: >10 minutes per iteration (timing out)

### What We Don't Know

**How long does SDPB actually need?**
- 30 minutes? (1800s)
- 1 hour? (3600s)
- More?

**Will more cores help?**
- Current: 8 cores
- Try: 16 cores? 32 cores?
- SDPB scales well with MPI parallelization

---

## Next Steps (Runtime Envelope Characterization)

Follow the workflow in `docs/SDPB_RUNTIME_ENVELOPE_2026-02-11.md`:

### Phase 1: Single-Point Characterization (Î”Ïƒ=0.518)

Run in order, stop at first success:

```bash
# 1. Baseline: 1800s timeout, 8 cores, 128G
bash jobs/submit_stage_a_runtime_envelope.sh

# Check result
sacct -j <JOBID> --format=JobID,State,ExitCode,Elapsed,MaxRSS,ReqMem
cat data/test_sufficient_memory.csv
tail -100 logs/test_sufficient_memory_<JOBID>.log
```

**Success criterion:** CSV contains `0.518000,1.41XXXX` (finite, not NaN, not 2.5)

**If timed out:**
```bash
# 2. Double timeout
TIMEOUT=3600 bash jobs/submit_stage_a_runtime_envelope.sh
```

**If still timed out:**
```bash
# 3. More cores + more time
TIMEOUT=3600 CPUS=16 MEM=160G WALLTIME=08:00:00 \
  bash jobs/submit_stage_a_runtime_envelope.sh
```

**Last resort (relax tolerance for profiling):**
```bash
TIMEOUT=3600 TOLERANCE=1e-3 bash jobs/submit_stage_a_runtime_envelope.sh
```

---

### Phase 2: Pilot + Full Array

Once single-point succeeds with known parameters (e.g., 3600s, 16 cores, 160G):

```bash
# 5-point pilot
sbatch --array=0,9,18,27,36 \
  --cpus-per-task=16 \
  --mem=160G \
  --time=12:00:00 \
  --export=ALL,SDPB_TIMEOUT=3600,STAGE_A_TOLERANCE=1e-4 \
  jobs/stage_a_pilot_sdpb.slurm

# Merge pilot results
bash jobs/merge_stage_a_pilot.sh

# If healthy, full array
sbatch --array=0-50 \
  --cpus-per-task=16 \
  --mem=160G \
  --time=12:00:00 \
  --export=ALL,SDPB_TIMEOUT=3600,STAGE_A_TOLERANCE=1e-4 \
  jobs/stage_a_sdpb.slurm
```

---

### Phase 3: Stage B

After Stage A completes:

```bash
# Merge + gate will validate Stage A and auto-submit Stage B
sbatch jobs/merge_stage_a_and_submit_b.slurm

# Or manually submit Stage B smoke test first
bash jobs/submit_stage_b_smoke.sh
```

---

## Git Status (Action Required)

**Local merge complete:**
```
âœ“ Branch merged to main locally
âœ“ Merge commit: 216890d
âœ“ All Codex commits now in main
```

**YOU NEED TO:**
```bash
# Push merge to GitHub
git push origin main

# Delete remote Codex branch
git push origin --delete codex/strict-failfast-stageb-snap-eps

# Verify
git branch -a | grep codex  # Should show nothing
```

---

## Documentation Updates Needed

- [x] Create this handoff document
- [ ] Update `CLAUDE.md` with new pipeline status
- [ ] Update `docs/PROGRESS.md` with merge info
- [ ] Archive old handoff (`HANDOFF_2026-02-10_ERROR_HANDLING_FIX.md`)

---

## Key Files Modified

### Source Code (4 files)
- `src/ising_bootstrap/lp/sdpb.py` - Strict termination reason handling
- `src/ising_bootstrap/scans/stage_a.py` - Fail-fast, timeout CLI
- `src/ising_bootstrap/scans/stage_b.py` - Epsilon anchoring, snap tolerance
- (No changes to `solver.py` - `FeasibilityResult.success` field already existed)

### SLURM Scripts (4 files)
- `jobs/stage_a_sdpb.slurm` - 128G, 12h, timeout env var
- `jobs/stage_b_sdpb.slurm` - Timeout + snap tolerance env vars
- `jobs/test_sufficient_memory.slurm` - 6h, timeout env var
- `jobs/merge_stage_a_and_submit_b.slurm` - Python validation gate

### New Helpers (6 files)
- `jobs/submit_stage_a_runtime_envelope.sh`
- `jobs/stage_a_pilot_sdpb.slurm`
- `jobs/merge_stage_a_pilot.sh`
- `jobs/stage_b_smoke_sdpb.slurm`
- `jobs/submit_stage_b_smoke.sh`
- `jobs/run_pipeline.sh` - Updated with env var forwarding

### Tests (3 files)
- `tests/test_lp/test_sdpb.py` - Updated for strict semantics
- `tests/test_scans/test_stage_a.py` - Added TestFailureHandling
- `tests/test_scans/test_stage_b.py` - Added epsilon anchoring tests

### Documentation (2 files)
- `docs/SDPB_RUNTIME_ENVELOPE_2026-02-11.md` - Runtime characterization workflow
- `docs/BRANCH_REVIEW_CHECKLIST_2026-02-11.md` - Merge criteria (completed)

---

## Expected Behavior After Timeout Is Configured

Once you find the right timeout (say 3600s with 16 cores):

### Good Logs
```
Stage A scan: 1 Î”Ïƒ points in [0.518, 0.518]
Loading block cache...
  Loaded 520474 extended block arrays from consolidated cache
[1/1] Î”Ïƒ = 0.5180
  Writing PMP JSON (470476 blocks, 66 vars) ...
  Running pmp2sdp (precision=1024) ...
  Running sdpb (16 cores, precision=1024, timeout=3600s) ...
  Binary search iteration 1: gap=1.500, excluded=True
  Binary search iteration 2: gap=1.250, excluded=False
  ...
  Î”Îµ_max = 1.412345  (8 iterations)

Scan complete. Results written to data/test_sufficient_memory.csv
```

**Result:**
```csv
delta_sigma,delta_eps_max
0.518000,1.412345
```

### Bad Logs (Timeout Still Too Short)
```
  Running sdpb (8 cores, precision=1024, timeout=1800s) ...
  ERROR: Solver failed while testing gap=1.500000 at Î”Ïƒ=0.518000.
  Failure: SDPB timed out after 1800s
```

**Result:**
```csv
delta_sigma,delta_eps_max
0.518000,nan
```

---

## Summary for Next Claude Instance

1. **Read this file** to understand current status
2. **Check git status**: merge should be pushed to GitHub, Codex branch deleted
3. **Run runtime envelope**: `bash jobs/submit_stage_a_runtime_envelope.sh`
4. **Iterate timeout** until single point succeeds (likely 1800-3600s)
5. **Run pilot** with successful parameters
6. **Run full array** if pilot is healthy

**Most likely path:** 3600s timeout with 16 cores will work.

---

## References

- **Runtime workflow:** `docs/SDPB_RUNTIME_ENVELOPE_2026-02-11.md`
- **Merge checklist:** `docs/BRANCH_REVIEW_CHECKLIST_2026-02-11.md`
- **Previous handoff:** `HANDOFF_2026-02-10_ERROR_HANDLING_FIX.md` (now superseded)
- **LP bug diagnosis:** `docs/LP_CONDITIONING_BUG.md`
- **MPI fix:** `docs/SDPB_MPI_FIX.md`

---

**Good luck! ðŸš€**
